from typing import Literal, Dict

# å¤©æ°£éš±å–»é¡å‹
'''
ä½ æ˜¯ä¸€å€‹å°è©±åˆ†æåŠ©æ‰‹ã€‚è«‹æ ¹æ“šè¼¸å…¥çš„èªå¥åˆ¤æ–·ä¸‰ä»¶äº‹ï¼š
1. æ•´é«”èªå¥çš„æƒ…ç·’é¡å‹ï¼ˆä¾‹å¦‚ï¼šå¤§ç¬‘ã€å®‰éœã€åè¦‹ã€ç¢ç¢å¿µã€åµæ¶ã€å¤§åµç­‰ï¼‰ï¼›
2. èªå¥ä¸­ã€Œä¸æ„‰å¿«æ°›åœã€çš„ç¸½æŒçºŒæ™‚é–“ï¼ˆä»¥ç§’ç‚ºå–®ä½ï¼Œä¼°ç®—å³å¯ï¼‰ï¼›
3. èªå¥ä¸­åè¦‹èªå¥å‡ºç¾çš„æ¬¡æ•¸ï¼ˆåè¦‹åŒ…å«æŒ‡è²¬ã€åˆ»æ¿å°è±¡æˆ–æ­§è¦–æ€§èªè¨€ï¼‰ã€‚

ä»¥ä¸‹æœ‰äº›å¸¸è¦‹çš„åè¦‹å¥å‹
ç•¶ä½ åµæ¸¬åˆ°ä»¥ä¸‹çš„å¥å¼ï¼Œè«‹åˆ†æè£¡é¢çš„å…§å®¹æ˜¯å¦æœ‰æ½›åœ¨çš„åè¦‹ï¼ç•¶ä½ é‡åˆ°é¡ä¼¼çš„å¥å­çš„æ™‚å€™ä¹Ÿè«‹æ³¨æ„ï¼š

å¥å¼ï¼š

ä½ æœ¬ä¾†å°±é€™æ¨£/ä½ ä¸€å®šæœƒæ€æ¨£æ€æ¨£â€¦.
å¦‚æœä¸è®€æ›¸ï¼Œä»¥å¾Œå°±ä¸€å®šâ‹¯â‹¯
æˆç¸¾ä¸å¥½ä¸€å®šæ˜¯å› ç‚ºâ€¦â€¦
å¥³ç”Ÿ/ç”·ç”Ÿä¸å¯ä»¥ â€¢
é‚£éº¼æ™šå›å®¶æœƒâ‹¯
XXçš„äººä¸€å®šéƒ½æ˜¯â‹¯â‹¯
é‚£éº¼èƒ–ä»¥å¾Œä¸€å®šâ‹¯â€¢
XXå­¸æ ¡ ç§‘ç³»ä¸€å®šâ‹¯
XXè·æ¥­éƒ½ â‹¯
ç‰¹å®šæ€§å‚¾å‘çš„äººéƒ½æ˜¯â‹¯â€¢
å–œæ­¡ â€¢â‹¯çš„äººä¸€å®šéƒ½â‹¯â‹¯
éƒ½æ²’æœ‰

è«‹è€ƒé‡ä»¥ä¸Šå¥å¼ã€‚

'''
WeatherType = Literal["æ™´å¤©", "é™°å¤©ï¼ˆâ˜ï¸ï¼‰", "å°é›¨ï¼ˆğŸŒ¦ï¼‰", "é›·é™£é›¨ï¼ˆâ›ˆï¼‰"]

def map_to_weather(emotion_label: str, duration: float, bias_count: int) -> WeatherType:
    """
    æ ¹æ“šæƒ…ç·’æ¨™ç±¤ã€è² é¢æ°›åœæŒçºŒæ™‚é–“èˆ‡åè¦‹æ¬¡æ•¸ï¼Œå›å‚³å¤©æ°£éš±å–»ã€‚
    """
    if emotion_label == "å¤§ç¬‘":
        return "æ™´å¤©"
    elif emotion_label == "å®‰éœ" and duration >= 30:
        return "é™°å¤©ï¼ˆâ˜ï¸ï¼‰"
    elif emotion_label in ["åè¦‹", "ç¢ç¢å¿µ", "åµæ¶"] and duration >= 60 and bias_count >= 2:
        return "å°é›¨ï¼ˆğŸŒ¦ï¼‰"
    elif emotion_label == "å¤§åµ" and duration >= 90 and bias_count >= 3:
        return "é›·é™£é›¨ï¼ˆâ›ˆï¼‰"
    else:
        return "æ™´å¤©"  # é è¨­ç‚ºæ™´å¤©

# æ¥æ”¶è¼¸å…¥ç¯„ä¾‹
# å‡è¨­é€™æ˜¯å¾ OpenAI API ç²å¾—çš„è¼¸å‡º
example_input = {
    "emotion_label": "åè¦‹",
    "duration": 65,  # å–®ä½ï¼šç§’
    "bias_count": 2
}

# å‘¼å«å°æ‡‰å‡½æ•¸
weather_result = map_to_weather(**example_input)
print(f"å°æ‡‰å¤©æ°£éš±å–»ï¼š{weather_result}")

import openai
import logging
import time

# è¨­å®š logging ä»¥ä¾¿èª¿è©¦
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger()

def test_do_with_sdk():
    # æ¨¡æ“¬ OpenAI å®¢æˆ¶ç«¯ï¼ˆé€™è£¡ä½¿ç”¨çš„æ˜¯ OpenAI SDK çš„æ–¹æ³•ï¼Œå·²ç¶“åŒ…å«åœ¨ `openai` æ¨¡å¡Šä¸­ï¼‰
    openai.api_key = "ä½ çš„ API é‡‘é‘°"  # æ›¿æ›ç‚ºä½ è‡ªå·±çš„é‡‘é‘°

    # é€™æ˜¯æ¨¡æ“¬çš„è¼¸å…¥å’ŒæŒ‡ä»¤
    inputs = "è«‹è§£é‡‹é‡å­è¨ˆç®—çš„åŸºæœ¬æ¦‚å¿µ"
    instructions = "ä½œç‚ºä¸€å€‹çŸ¥è­˜åŠ©æ‰‹ï¼Œè§£é‡‹é‡å­è¨ˆç®—ã€‚"
    
    tools = [
        {"name": "tool1", "description": "A sample tool for demonstration purposes."}
    ]
    model_name = "gpt-4"  # æˆ–è€…ä½¿ç”¨å…¶ä»–æ¨¡å‹åç¨±ï¼Œå¦‚ "assistant"

    # å–å¾—ä¸Šå‚³çš„æ–‡ä»¶
    uploaded_files = openai.files.list()
    uploaded_files_data = uploaded_files['data']
    uploaded_fileids = [file['id'] for file in uploaded_files_data]
    logger.debug("Uploaded file IDs: ", uploaded_fileids)

    # å‰µå»ºçŸ¥è­˜åŠ©æ‰‹
    assis = openai.beta.assistants.create(
        name="Knowledge Assistant",
        instructions=instructions,
        model=model_name,
        tools=tools,
        file_ids=uploaded_fileids,
    )

    # å‰µå»ºä¸€å€‹è¨è«–ä¸²
    thread = openai.beta.threads.create()

    # ç™¼é€è¨Šæ¯åˆ°è¨è«–ä¸²
    openai.beta.threads.messages.create(
        thread_id=thread['id'],
        role="user",
        content=inputs,
    )

    # å‰µå»ºåŸ·è¡Œä»»å‹™
    run = openai.beta.threads.runs.create(
        thread_id=thread['id'], assistant_id=assis['id']
    )

    # ç­‰å¾…ä»»å‹™å®Œæˆ
    while True:
        retrieved_run = openai.beta.threads.runs.retrieve(
            thread_id=thread['id'], run_id=run['id']
        )
        logger.debug("Retrieved run: ", retrieved_run)
        if retrieved_run['status'] == "completed":
            break
        time.sleep(1)  # ç­‰å¾… 1 ç§’å¾Œå†æª¢æŸ¥ç‹€æ…‹

    # ç²å–è¨è«–å…§å®¹
    thread_messages = openai.beta.threads.messages.list(thread['id'])
    logger.debug("Thread messages: ", thread_messages['data'])

    # è¿”å›æœ€åˆçš„å›æ‡‰å…§å®¹
    return thread_messages['data'][0]['content'][0]['text']['value']

result = test_do_with_sdk()
print("Test result:", result)
